---
title: "Decision trees homework, Colin Scotland"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    css: ../../../styles.css
  pdf_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
```


<br>
In this homework we will create a decision tree to see which factors are useful in predicting whether or not a passenger on the titanic will survive.  


Run the code below before you begin: 


```{r, warning = FALSE, message = FALSE}
library(rpart)
library(rpart.plot)
library(tidyverse)


titanic_set <- read_csv('data/titanic_decision_tree_data.csv')

shuffle_index <- sample(1:nrow(titanic_set))

# shuffle the data so class order isn't in order - need this for training/testing split later on 
titanic_set <- titanic_set[shuffle_index, ]
```

<br>

**Data Dictionary**

  * **sex**: Biological Sex, male or female  
  * **age_status**: adult or child (child defined as under 16)  
  * **class** : Ticket class, 1 = 1st (Upper class), 2 = 2nd (Middle Class), 3 = 3rd (Lower Class)    
  * **port_embarkation**: C = Cherbourg, Q = Queenstown, S = Southampton  
  * **sibsp** : number of siblings / spouses aboard the Titanic   
  * **parch**: number of parents / children aboard the Titanic. Some children travelled only with a nanny, therefore parch=0 for them. 
  * **survived_flag** : did they survive, 0 = No, 1 = Yes  



# MVP 


## Question 1  

<br> 
Cleaning up the data is always the first step. Do the following: 

  * Take only observations which have a `survived` flag (i.e. that aren't missing)  
  * Turn your important variables into factors (sex, survived, pclass, embarkation)  
  * Create an `age_status` variable which groups individuals under (and including) 16 years of age into a category called "child" category and those over 16 into a category called "adult".  
  * Drop the NA  
  * Drop any variables you don't need (`X1`, `passenger_id`, `name`, `ticket`, `far`, `cabin`)  



```{r}
titanic_set <- titanic_set %>% janitor::clean_names()
  
```


```{r}
titanic_set %>% 
  summarise(across(.cols = everything(), ~ sum(is.na(.))))
```
Plenty of NAs, but not necessarily in important columns.  The ones in the
`survived` column can be dropped.

```{r}
titanic_set_clean <- titanic_set %>% 
  select(-c(x1, passenger_id, name, ticket, fare, cabin)) %>% 
  drop_na(c(survived, age)) %>% 
  mutate(survived = if_else(survived == 1, "survived", "died"),
         across(.cols = c(sex, survived, pclass, embarked), ~ as.factor(.)),
         if_else(age <= 16, "child", "adult"))
  
           
```





<!-- If you need help doing this, the code is below, but please try it yourself first so you can learn! -->

<!-- <br> -->
<!-- <details> -->
<!-- <summary>**Data Cleaning Code** </summary> -->
<br>

```{r}
# titanic_clean <- titanic_set %>%
#   filter(survived %in% c(0,1)) %>%
# # Convert to factor level
# 	mutate(sex = as.factor(sex), 
# 	       age_status = as.factor(if_else(age <= 16, "child", "adult")),
#          class = factor(pclass, levels = c(3,2,1), labels = c("Lower", "Middle", "Upper")), 
# 	       survived_flag = factor(survived, levels = c(0,1), labels = c("No", "Yes")), 
# 	       port_embarkation = as.factor(embarked)) %>%
#   select(sex, age_status, class, port_embarkation, sib_sp, parch, survived_flag) %>%
#   na.omit()
```
</details>


<br>

## Question 2  

<br> 
Have a look at your data and create some plots to ensure you know what you're working with before you begin. Write a summary of what you have found in your plots. Which variables do you think might be useful to predict whether or not people are going to die? Knowing this before you start is the best way to have a sanity check that your model is doing a good job.  

```{r}
library(GGally)
```


```{r}
ggpairs(titanic_set_clean)
```
It looks like survival depends strongly on sex, embarked and pclass.  At this 
stage it looks like higher numbers in 3rd class died than in 2nd and 1st class, 
i.e. people travelling 1st class were given priority.

It also looks like there's a real bias in survival rates for one particular 
gender, although it isn't clear which.



<br>

## Question 3  

<br> 
Now you can start to build your model. Create your testing and training set using an appropriate split. Check you have balanced sets. Write down why you chose the split you did and produce output tables to show whether or not it is balanced. [**Extra** - if you want to force balanced testing and training sets, have a look at the `stratified()` function in package `splitstackshape` (you can specify multiple variables to stratify on by passing a vector of variable names to the `group` argument, and get back testing and training sets with argument `bothSets = TRUE`)]


There are 714 observations.  10% of this would be 71 rows, so 20% would be a 
better size (142 rows) to use as a test set.

```{r}
n_data <- nrow(titanic_set_clean)

test_index <- sample(1:n_data, size = n_data * 0.2) # set the test set size

titanic_test <- slice(titanic_set_clean, test_index)    # test set setup

titanic_train <- slice(titanic_set_clean, -test_index)  # train set setup

titanic_test %>% 
  janitor::tabyl(survived)

titanic_train %>% 
  janitor::tabyl(survived)
```
The `tabyl` function shows that there are similar proportions of survivors in 
both test and train data sets.




## Question 4      

<br> 
Create your decision tree to try and predict survival probability using an appropriate method, and create a decision tree plot.

```{r}
titanic_fit <- rpart(
  formula = survived ~ .,
  data = titanic_train,
  method = "class"
)

rpart.plot(titanic_fit,
           yesno = 2,
           fallen.leaves = TRUE,
           faclen = 6,
           digits = 3,
           box.palette = "Oranges",
           shadow.col = "darkgrey",
           tweak = 1.3
           )
```



## Question 5    

<br> 
Write down what this tells you, in detail. What variables are important? What does each node tell you? Who has the highest chance of surviving? Who has the lowest? Provide as much detail as you can.    

The figures in the root node suggest that overall there was a **40% chance of** 
**surviving the Titanic** disaster based on our data set.  The most important 
factors for survival were;

* sex 
* age
* passenger class
* no. siblings / spouse on board

In more detail;

* 80% of men died, only 20% survived  
* only 17% of males over 9.5 years old survived
* 68% of males under 9.5 survived
* 73% of women survived overall
* Of these surviving women, 94% were 1st or 2nd class passengers
* Only 41% of 3rd class passengers who were women survived, 75% of whom were
younger than 5.5 years old
* Only 36% of the 41% women surviving from 3rd class were older than 5.5 years 
old
* 21% of these surviving 3rd class women passengers were travelling with a 
spouse or sibling
* 53% of the 3rd class women passengers who were not travelling with a spouse
or sibling died - 89% of these were older than 30.3 years old
* of these 53%, 58% who were under 30.3 years old survived

The most likely group to survive were boys under 9.5 years old who were travelling
with 1 or 0 siblings (100% survived).  The next most likely to survive were 
women in 1st and 2nd class(94%), then girls in 3rd class (75%).

The most likely group to perish was women over the age of 30.3 who were travelling 
in 3rd class without their spouse or siblings (89%), followed by males over the age
of 9.5 years old (83%) and boys under 9.5 years old who were travelling with 2 
or more siblings(87%).


<br>

## Question 6     

<br>  
Test and add your predictions to your data. Create a confusion matrix. Write down in detail what this tells you for this specific dataset.  

```{r}
library(modelr)

```


Add predictions;
```{r}
titanic_pred <- titanic_test %>% 
  add_predictions(titanic_fit, type = "class")
  
```

Select relevant data;
```{r}
titanic_pred %>% 
  select(survived, pred, pclass, sib_sp, sex, age)
```

```{r}
library(yardstick)
```

```{r}
titanic_conf_mat <- titanic_pred %>%
              conf_mat(truth = survived, estimate = pred)

titanic_conf_mat
```

The confusion matrix above shows that the model correctly predicted a death
75 times out of the 142 rows in the test set, and correctly predicted survival
on 42 occasions.

The model incorrectly predicted survival 6 times (false positive) and incorrectly
predicted death 19 times (false negative).

The overall accuracy relative to this data set is;
```{r}
accuracy <- titanic_pred %>%
 accuracy(truth = survived, estimate = pred)

accuracy 
```
 The model is around 82% accurate with this test data.
 
 
 **Note: Sometimes the confusion table will label columns/rows alphabetically
 if it cannot decide what label is supposed to be true and which is false.  It
 is often better to have these parameters labelled simply as '0' and '1'.

# Extension  

See how a `ranger()` random forest classifier compares with a single decision tree in terms of performance. Can you tune the values of the `mtry`, `splitrule` and `min.node.size` hyperparameters? Which variables in the dataset turn out to be most important for your best model? The `Kappa` metric might be the best one to focus on if you want to improve performance for an imbalanced data set. Do some research on the definition of `Kappa` before you start.

We provide the code in the dropdown below if you get stuck, but still want to play around with this (note that run time can be up to 5-10 mins for the tuning). **Save your notebook before you begin** in case you need to force quit your session!

<br>
<details>
<summary>**Code**</summary>

```{r, eval=FALSE}
library(ranger)

control <- trainControl(
  method = "repeatedcv", 
  number = 5, 
  repeats = 10
)

tune_grid = expand.grid(
  mtry = 1:6,
  splitrule = c("gini", "extratrees"),
  min.node.size = c(1, 3, 5)
)
```

```{r, eval=FALSE}
rf_tune <- train(
  survived_flag ~ ., 
  data = titanic_train, 
  method = "ranger",
  metric = "Kappa",
  num.trees = 1000,
  importance = "impurity",
  tuneGrid = tune_grid, 
  trControl = control
)

plot(rf_tune)
rf_tune
```
</details>
<br>

