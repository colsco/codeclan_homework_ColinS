---
title: "R Notebook"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

```{r, echo = FALSE}
library(tidyverse)
library(ggfortify)
library(modelr)
library(GGally)
library(mosaic)
library(here)
library(lubridate)
library(janitor)



here::here()
```

```{r}
avocados <- read_csv(here("1_weekend_homework_part1/data/avocado.csv")) %>% 
  janitor::clean_names()
avocados
```

Check for NAs in the data set;

```{r}
avocados %>% 
  summarise(across(.cols = everything(), ~ sum(is.na(.))))
```

So there are no NAs to consider.

## Make a test set

The data consists of > 18k observations, so there should be plenty of capacity
to create a test set.  10% of 18k is around 1800 observations, which sounds like
a reasonable size for a test set.

Make a test index using 10% of the data;
```{r}
avocado_row_count <- nrow(avocados)

test_index <- sample(1:avocado_row_count, size = avocado_row_count * 0.1)
```

Then create the test and train data sets using this index;
```{r}
avo_test <- slice(avocados, test_index)
avo_train <- slice(avocados, -test_index)
```

## Process the Data

#### Seasonality

The discussion relates to the growth and harvest of a fruit, so there's a good 
chance that there's a seasonal element to the price that could be a significant 
factor;
```{r}
avo_train <- avo_train %>% 
  mutate(month = month(as.POSIXlt(date), label = TRUE, abbr = TRUE))
 
```

```{r}
avo_train %>% 
  select(month, average_price) %>% 
  group_by(month) %>% 
  summarise(mean_price_per_month = mean(average_price)) %>% 
  ggplot() +
  aes(x = month, y = mean_price_per_month) +
  geom_line(group = 1) +
  geom_point() +
  labs(title = "Mean Average Avocado Price per Month\nJan 2015 - March 2018",
       x = "Month",
       y = "Mean Average Price") +
  theme_bw() + 
  theme(title = element_text(face = "bold"))
```

<br><br>
This plot suggests that there is indeed some seasonality.  It would be worth
retaining the `month` column to check in the model later, but there's no need to 
keep the level of detail contained in the `date` column.  Variation by day is 
too much detail.

#### Regions

Considering `region`, there are several values that are very ambiguous such as 
`plains`, `WestTexNewMexico`, `SouthEast`.  Although regional variations may be
a significant factor worthy of inclusion in a model, it would be difficult to rationally separate all of the areas into discrete constituent states, so region 
will also be removed.

```{r}
avo_train <- avo_train %>% 
  select(-c(date, region))
```


#### Other Considerations

The `x1` column appears to be an identifier of individual observations and will
not influence the model, so can be removed safely.
```{r}
avo_train <- avo_train %>% 
  select(-x1)
```


It looks likely that there will be aliases in bag sizes;
```{r}
alias(lm(average_price ~ ., data = avo_train))
```

The alias function shows nothing at this point, but it looks like 
`total_bags` = `small_bags` + `large_bags` + `x_large_bags` - verify this
a different way, bearing in mind that R is not a perfect calculator when 
trying to compare floating point numbers;
```{r}
avo_train %>% 
  mutate(bag_check = 
           as.integer(total_bags - (small_bags + large_bags + x_large_bags))) %>% 
  distinct(bag_check)
```


So it looks like the supposition:

`total_bags` = `small_bags` + `large_bags` + `x_large_bags`

is true - R's lack of precision in performing floating point calculations leads
to rounding errors within +/- 1, which is what is shown in the results.

In conclusion, we can safely remove `total_bags` from the data set, because this
can be calculated if necessary.

```{r}
avo_train <- avo_train %>% 
  select(-total_bags)
```

`x4046`, `x4225` or `x4770` are Price Lookup Codes:

(from https://loveonetoday.com/how-to/identify-hass-avocados/)

The most commonly sold sizes of fresh Hass avocado can be identified by their 
Price Look Up code or PLU or sticker.

* Small/Medium Hass Avocado (~3-5oz avocado) | #4046 Avocado
* Large Hass Avocado (~8-10oz avocado) | #4225 Avocado
* Extra Large Hass Avocado (~10-15oz avocado) | #4770 Avocado

One last change is to set non-numeric variables as factors for processing;
```{r}
avo_train <- avo_train %>% 
  mutate(type = as.factor(type),
         month = as.factor(month))
```


## First Predictor

Check the remaining variables for signs of correlation in order to determine
possible predictors for the model;

```{r}
ggpairs(avo_train)
```


## mod1a ----

From the plot it appears as though `type` may be an important factor;

```{r}
avo_train %>% 
  ggplot() +
  aes(x = type, y = average_price) +
  geom_boxplot() +
  theme_bw() +
  labs(title = "Average Price v Avocado Type",
       x = "Avocado Type",
       y = "Average Price")
```


`type` is a categorical variable, so should be checked for significance using 
ANOVA both with and without `type` included;
```{r}
anova(lm(average_price ~ . -type, data = avo_train))
```

```{r}
anova(lm(average_price ~ ., data = avo_train))
```


It looks like type *is* statistically significant.  So the first model could be;
```{r}
mod1a <- lm(average_price ~ type, data = avo_train)
```

How does this look;
```{r}
summary(mod1a)
```

This suggests that 37% of the variance in our model could be explained by `type`.

Run the diagnostic plots;
```{r}
autoplot(mod1a)
```

These look acceptable;

* The Residuals v Fitted are spread around 0 with a fairly flat line
* Q-Q plot is not perfect, but is on the line for the most part
* Scale - Location are in a band above the x-axis with only a very slight funnel
effect evident.

## mod1b ----

At the very start it looked like `month` might also be a significant factor due 
to the seasonality of avocado growth and harvesting;

```{r}
mod1b <- lm(average_price ~ month, data = avo_train)
```

Check ANOVA with and without `month`;
```{r}
anova(lm(average_price ~ . -month, data = avo_train))
```



```{r}
anova(mod1b)
```

```{r}
autoplot(mod1b)
```

These don't look perfect, but once again the residuals v fitted are spread 
across 0 with a fairy flat line, and the Q-Q plot is on the line for the mid-
section of the points.

```{r}
summary(mod1b)
```
It looks like some of the months have a significant effect on average_price, 
although the overall R-squared is poor.  If they are to be included then *all* 
months will be included.

Double check significance; run an ANOVA against the null model (intercept only);
```{r}
null_model <- lm(average_price ~ 1, data = avo_train)
month_model <- lm(average_price ~ month, data = avo_train)

anova(null_model, month_model)
```

So `month` is significant.


## mod1c ----

It would make sense that avocado size would impact on price:

```{r}
mod1c <- lm(average_price ~ x4046, data = avo_train)
```


```{r}
autoplot(mod1c)
```

The diagnostic plots really don't look acceptable.  There are signs of non-normal
distribution in every plot.

## mod1d ----

Try `x4225`;
```{r}
mod1d <- lm(average_price ~ x4225, data = avo_train)
```


```{r}
autoplot(mod1d)
```



This is also unacceptable; try `x4770`

## mod1e ----

```{r}
mod1e <- lm(average_price ~ x4770, data = avo_train)
```


```{r}
autoplot(mod1d)
```


`x4770` is also unacceptable in isolation.

It looks like avocado size *might* be significant based on the ANOVA results
earlier, but they don't fit the linear model.

## Model 1 ----

So `type` looks like the most promising predictor so far, giving;
```{r}
avo_model1 <- lm(average_price ~ type, data = avo_train)
```


## Second Predictor 

Looking at residuals;
```{r}
avo_residuals <- avo_train %>% 
  add_residuals(mod1a) %>% 
  select(-c(average_price, type))

avo_residuals_numeric <- avo_residuals %>%
  select_if(is.numeric)

avo_residuals_nonnumeric <- avo_residuals %>%
  select_if(function(x) !is.numeric(x))

avo_residuals_nonnumeric$resid <- avo_residuals$resid
```

```{r}
ggpairs(avo_residuals_numeric)
```

```{r}
ggpairs(avo_residuals_nonnumeric)
```

Month(as tried in mod1b) looks like it's the next best against `resid`, although 
`year` also looks like it might be a factor.  

## mod2a ----

Add month into the model, since the ANOVA etc above did show significance.


```{r}
mod2a <- lm(average_price ~ type + month, data = avo_train)
```


```{r}
summary(mod2a)
```


The adjusted R-squared indicates that 43% of the variance in our model could be 
explained by `type` + `month`.

```{r}
autoplot(mod2a)
```

The diagnostic plots are generally acceptable for this model;

* Fitted v Residuals are spread across 0 with a fairly horizontal line.
* Q-Q plot shows around 75% of the points are on the line
* Scale - Location does not show any extreme funnelling effect

How does this compare with using `year` as the second predictor?

## mod2b ----

```{r}
mod2b <- lm(average_price ~ type + year, data = avo_train)
```


```{r}
summary(mod2b)
```

This shows that `year` has less of an effect than `month`.  Make model 2 with 
`month`;

## Model 2 ----

```{r}
avo_model2 <- lm(average_price ~ type + month, data = avo_train)
```


And look at the residuals again;
```{r}
avo_residuals <- avo_train %>% 
  add_residuals(mod1a) %>% 
  select(-c(average_price, type, month))

avo_residuals_numeric <- avo_residuals %>%
  select_if(is.numeric)

avo_residuals_nonnumeric <- avo_residuals %>%
  select_if(function(x) !is.numeric(x))

avo_residuals_nonnumeric$resid <- avo_residuals$resid
```


```{r}
ggpairs((avo_residuals_numeric))
```

Looking at the correlation against `resid` it doesn't look like there are any 
other very highly significant contributors.  All correlation coefficients are
below 0.1 in magnitude.

This suggests that the final model for average pricing of avocados is model 2.

$$ average\_price \sim type + month $$

This suggests that the average price of avocados varies as a function of
the type of avocado and the month of the year.  This seems fairly sensible.
